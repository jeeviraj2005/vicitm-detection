{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9426707,"sourceType":"datasetVersion","datasetId":5584155}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip -q install ultralytics==8.3.50\n\nimport os, shutil, glob, zipfile, random\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport cv2\nimport yaml\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nfrom ultralytics import YOLO\n\n# —— set seeds for reproducibility\nrandom.seed(42)\n\n# —— PATHS (edit RAW if your dataset lives elsewhere)\nRAW  = Path(\"/kaggle/input/c2a-dataset/C2A_Dataset/new_dataset3\")   # your original dataset (READ-ONLY)\nPROC = Path(\"/kaggle/working/c2a_preprocessed\")                      # will hold preprocessed dataset (READ/WRITE)\nROOT = Path(\"/kaggle/working\")\nRUNS = ROOT / \"runs\"\nART  = ROOT / \"artifacts\"   # will store before/after images, predictions, zips, etc.\nfor p in [PROC, ART]:\n    p.mkdir(parents=True, exist_ok=True)\n\nprint(\"RAW :\", RAW)\nprint(\"PROC:\", PROC)\nprint(\"ROOT:\", ROOT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T12:17:09.798796Z","iopub.execute_input":"2025-08-23T12:17:09.798988Z","iopub.status.idle":"2025-08-23T12:18:29.966833Z","shell.execute_reply.started":"2025-08-23T12:17:09.798972Z","shell.execute_reply":"2025-08-23T12:18:29.966140Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nRAW : /kaggle/input/c2a-dataset/C2A_Dataset/new_dataset3\nPROC: /kaggle/working/c2a_preprocessed\nROOT: /kaggle/working\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# fresh copy of dataset to working dir\nshutil.rmtree(PROC, ignore_errors=True)\nshutil.copytree(RAW, PROC)\nprint(\"✅ Copied RAW → PROC:\", PROC)\n\ndef preprocess_images(image_dir):\n    paths = sorted(glob.glob(str(Path(image_dir) / \"*.*\")))\n    for img_path in tqdm(paths, desc=f\"Preprocess {image_dir}\"):\n        try:\n            img = cv2.imread(img_path)\n            if img is None:\n                # bad read → delete the image (keeps labels untouched)\n                os.remove(img_path)\n                continue\n            img_resized = cv2.resize(img, (640, 640), interpolation=cv2.INTER_AREA)\n            cv2.imwrite(img_path, img_resized)\n        except Exception:\n            # any issue → drop the image\n            if os.path.exists(img_path):\n                os.remove(img_path)\n\nfor split in [\"train\", \"val\", \"test\"]:\n    preprocess_images(PROC / split / \"images\")\n\nprint(\"✅ Preprocessing done: resized to 640×640 & cleaned corrupts.\")\n\n# ➜ ZIP the preprocessed dataset for download\nzip_pre = ROOT / \"c2a_preprocessed.zip\"\nif zip_pre.exists(): zip_pre.unlink()\nshutil.make_archive(str(zip_pre).replace(\".zip\",\"\"), 'zip', PROC)\nprint(\"📦 Preprocessed dataset ready:\", zip_pre)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T12:18:50.075648Z","iopub.execute_input":"2025-08-23T12:18:50.075920Z","iopub.status.idle":"2025-08-23T12:33:55.647989Z","shell.execute_reply.started":"2025-08-23T12:18:50.075894Z","shell.execute_reply":"2025-08-23T12:33:55.647223Z"}},"outputs":[{"name":"stderr","text":"Preprocess /kaggle/working/c2a_preprocessed/train/images: 100%|██████████| 6129/6129 [03:46<00:00, 27.01it/s]\nPreprocess /kaggle/working/c2a_preprocessed/val/images: 100%|██████████| 2043/2043 [01:13<00:00, 27.77it/s]\nPreprocess /kaggle/working/c2a_preprocessed/test/images: 100%|██████████| 2043/2043 [01:17<00:00, 26.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"✅ Preprocessing done: resized to 640×640 & cleaned corrupts.\n📦 Preprocessed dataset ready: /kaggle/working/c2a_preprocessed.zip\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def yolo_draw(img_bgr, label_path, class_names=None):\n    img = img_bgr.copy()\n    h, w = img.shape[:2]\n    if os.path.exists(label_path):\n        with open(label_path) as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) < 5: \n                    continue\n                cls, xc, yc, bw, bh = map(float, parts[:5])\n                x1 = int((xc - bw/2) * w); y1 = int((yc - bh/2) * h)\n                x2 = int((xc + bw/2) * w); y2 = int((yc + bh/2) * h)\n                cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 2)\n                label = str(int(cls)) if not class_names else class_names[int(cls)]\n                cv2.putText(img, label, (x1, max(15, y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n    return img\n\n# —— EDIT if your class names differ\nCLASS_NAMES = [\"standing\",\"sitting\",\"walking\",\"lying\"]\n\ndef save_before_after_samples(split=\"train\", n=5):\n    (ART / \"before_after\").mkdir(exist_ok=True, parents=True)\n    raw_imgs  = sorted(glob.glob(str(RAW  / split / \"images\" / \"*.*\")))\n    proc_imgs = sorted(glob.glob(str(PROC / split / \"images\" / \"*.*\")))\n    if not raw_imgs or not proc_imgs:\n        print(f\"No images found for split '{split}'.\")\n        return\n    raw_pick  = random.sample(raw_imgs,  min(n, len(raw_imgs)))\n    proc_pick = [str(PROC / split / \"images\" / Path(p).name) for p in raw_pick]\n\n    # visualize and save side-by-side grids\n    plt.figure(figsize=(16, 6))\n    plt.suptitle(f\"{split.upper()} — BEFORE (raw)   |   AFTER (preprocessed)\", fontsize=14)\n    for i, (r, p) in enumerate(zip(raw_pick, proc_pick)):\n        # raw\n        img_r = cv2.cvtColor(cv2.imread(r), cv2.COLOR_BGR2RGB)\n        lab_r = r.replace(\"/images/\", \"/labels/\"); lab_r = os.path.splitext(lab_r)[0] + \".txt\"\n        img_r = cv2.cvtColor(yolo_draw(cv2.imread(r), lab_r, CLASS_NAMES), cv2.COLOR_BGR2RGB)\n\n        # after\n        img_p = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n        lab_p = p.replace(\"/images/\", \"/labels/\"); lab_p = os.path.splitext(lab_p)[0] + \".txt\"\n        img_p = cv2.cvtColor(yolo_draw(cv2.imread(p), lab_p, CLASS_NAMES), cv2.COLOR_BGR2RGB)\n\n        plt.subplot(2, n, i+1)\n        plt.imshow(img_r); plt.axis(\"off\"); plt.title(\"before\")\n        plt.subplot(2, n, i+1+n)\n        plt.imshow(img_p); plt.axis(\"off\"); plt.title(\"after\")\n\n        # also save individual files for download\n        cv2.imwrite(str(ART / \"before_after\" / f\"before_{i}.jpg\"), cv2.cvtColor(img_r, cv2.COLOR_RGB2BGR))\n        cv2.imwrite(str(ART / \"before_after\" / f\"after_{i}.jpg\"),  cv2.cvtColor(img_p, cv2.COLOR_RGB2BGR))\n    plt.tight_layout()\n    plt.show()\n\nsave_before_after_samples(\"train\", n=5)\n\n# zip before/after for download\nbefore_after_zip = ROOT / \"before_after_samples.zip\"\nif before_after_zip.exists(): before_after_zip.unlink()\nshutil.make_archive(str(before_after_zip).replace(\".zip\",\"\"), 'zip', ART / \"before_after\")\nprint(\"📦 Before/After samples zip:\", before_after_zip)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:13:38.795224Z","iopub.execute_input":"2025-08-23T13:13:38.795980Z","iopub.status.idle":"2025-08-23T13:13:38.870269Z","shell.execute_reply.started":"2025-08-23T13:13:38.795953Z","shell.execute_reply":"2025-08-23T13:13:38.869725Z"}},"outputs":[{"name":"stdout","text":"No images found for split 'train'.\n📦 Before/After samples zip: /kaggle/working/before_after_samples.zip\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def yolo_draw(img_bgr, label_path, class_names=None):\n    \"\"\"Draw YOLO bounding boxes if labels exist.\"\"\"\n    img = img_bgr.copy()\n    h, w = img.shape[:2]\n    if os.path.exists(label_path):\n        with open(label_path) as f:\n            for line in f:\n                parts = line.strip().split()\n                if len(parts) < 5: \n                    continue\n                cls, xc, yc, bw, bh = map(float, parts[:5])\n                x1 = int((xc - bw/2) * w); y1 = int((yc - bh/2) * h)\n                x2 = int((xc + bw/2) * w); y2 = int((yc + bh/2) * h)\n                cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 2)\n                label = str(int(cls)) if not class_names else class_names[int(cls)]\n                cv2.putText(img, label, (x1, max(15, y1-5)), \n                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n    return img\n\n# —— EDIT if your class names differ\nCLASS_NAMES = [\"standing\",\"sitting\",\"walking\",\"lying\"]\n\ndef save_before_after_samples(split=\"train\", n=5):\n    (ART / \"before_after\").mkdir(exist_ok=True, parents=True)\n    raw_imgs  = sorted(glob.glob(str(RAW  / split / \"images\" / \"*.*\")))\n    proc_imgs = sorted(glob.glob(str(PROC / split / \"images\" / \"*.*\")))\n    if not raw_imgs or not proc_imgs:\n        print(f\"No images found for split '{split}'.\")\n        return\n    raw_pick  = random.sample(raw_imgs,  min(n, len(raw_imgs)))\n    proc_pick = [str(PROC / split / \"images\" / Path(p).name) for p in raw_pick]\n\n    # visualize and save side-by-side grids\n    plt.figure(figsize=(16, 6))\n    plt.suptitle(f\"{split.upper()} — BEFORE (raw)   |   AFTER (preprocessed)\", fontsize=14)\n    for i, (r, p) in enumerate(zip(raw_pick, proc_pick)):\n        # before (raw) — NO bounding boxes\n        img_r = cv2.cvtColor(cv2.imread(r), cv2.COLOR_BGR2RGB)\n\n        # after (preprocessed) — WITH bounding boxes\n        img_p = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n        lab_p = p.replace(\"/images/\", \"/labels/\"); lab_p = os.path.splitext(lab_p)[0] + \".txt\"\n        img_p = cv2.cvtColor(yolo_draw(cv2.imread(p), lab_p, CLASS_NAMES), cv2.COLOR_BGR2RGB)\n\n        # plot\n        plt.subplot(2, n, i+1)\n        plt.imshow(img_r); plt.axis(\"off\"); plt.title(\"before\")\n        plt.subplot(2, n, i+1+n)\n        plt.imshow(img_p); plt.axis(\"off\"); plt.title(\"after\")\n\n        # also save individual files\n        cv2.imwrite(str(ART / \"before_after\" / f\"before_{i}.jpg\"), cv2.cvtColor(img_r, cv2.COLOR_RGB2BGR))\n        cv2.imwrite(str(ART / \"before_after\" / f\"after_{i}.jpg\"),  cv2.cvtColor(img_p, cv2.COLOR_RGB2BGR))\n\n    plt.tight_layout()\n    plt.show()\n\nsave_before_after_samples(\"train\", n=5)\n\n# zip before/after for download\nbefore_after_zip = ROOT / \"before_after_samples.zip\"\nif before_after_zip.exists(): before_after_zip.unlink()\nshutil.make_archive(str(before_after_zip).replace(\".zip\",\"\"), 'zip', ART / \"before_after\")\nprint(\"📦 Before/After samples zip:\", before_after_zip)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:13:07.325307Z","iopub.execute_input":"2025-08-23T13:13:07.325638Z","iopub.status.idle":"2025-08-23T13:13:07.402138Z","shell.execute_reply.started":"2025-08-23T13:13:07.325610Z","shell.execute_reply":"2025-08-23T13:13:07.401407Z"}},"outputs":[{"name":"stdout","text":"No images found for split 'train'.\n📦 Before/After samples zip: /kaggle/working/before_after_samples.zip\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"data_yaml = {\n    \"path\": str(PROC),\n    \"train\": \"train/images\",\n    \"val\":   \"val/images\",\n    \"test\":  \"test/images\",\n    \"names\": {i:n for i,n in enumerate(CLASS_NAMES)}\n}\nyaml_path = ROOT / \"c2a_data.yaml\"\nwith open(yaml_path, \"w\") as f:\n    yaml.safe_dump(data_yaml, f, sort_keys=False)\n\nprint(\"✅ data.yaml written to:\", yaml_path)\nprint(yaml_path.read_text())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T12:54:19.127636Z","iopub.execute_input":"2025-08-23T12:54:19.128204Z","iopub.status.idle":"2025-08-23T12:54:19.134562Z","shell.execute_reply.started":"2025-08-23T12:54:19.128182Z","shell.execute_reply":"2025-08-23T12:54:19.133915Z"}},"outputs":[{"name":"stdout","text":"✅ data.yaml written to: /kaggle/working/c2a_data.yaml\npath: /kaggle/working/c2a_preprocessed\ntrain: train/images\nval: val/images\ntest: test/images\nnames:\n  0: standing\n  1: sitting\n  2: walking\n  3: lying\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"pip uninstall -y ray\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:32:38.059958Z","iopub.execute_input":"2025-08-23T13:32:38.060296Z","iopub.status.idle":"2025-08-23T13:32:41.882701Z","shell.execute_reply.started":"2025-08-23T13:32:38.060256Z","shell.execute_reply":"2025-08-23T13:32:41.881834Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: ray 2.47.1\nUninstalling ray-2.47.1:\n  Successfully uninstalled ray-2.47.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import ultralytics\nfrom ultralytics.utils import callbacks\n\n# Remove the raytune callback that is causing issues\nif \"on_fit_epoch_end\" in callbacks.default_callbacks:\n    del callbacks.default_callbacks[\"on_fit_epoch_end\"]\n\nprint(\"✔ Disabled RayTune callback\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:34:02.377807Z","iopub.execute_input":"2025-08-23T13:34:02.378140Z","iopub.status.idle":"2025-08-23T13:34:02.383869Z","shell.execute_reply.started":"2025-08-23T13:34:02.378110Z","shell.execute_reply":"2025-08-23T13:34:02.383193Z"}},"outputs":[{"name":"stdout","text":"✔ Disabled RayTune callback\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import ultralytics\nimport ultralytics.utils.callbacks as cb\n\n# Remove RayTune callback completely (hard delete)\nif \"on_fit_epoch_end\" in cb.default_callbacks:\n    cb.default_callbacks.pop(\"on_fit_epoch_end\")\nprint(\"✔ RayTune callback removed safely\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T13:56:41.656097Z","iopub.execute_input":"2025-08-23T13:56:41.656392Z","iopub.status.idle":"2025-08-23T13:56:41.661743Z","shell.execute_reply.started":"2025-08-23T13:56:41.656345Z","shell.execute_reply":"2025-08-23T13:56:41.661012Z"}},"outputs":[{"name":"stdout","text":"✔ RayTune callback removed safely\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import os, shutil\nfrom ultralytics import YOLO\nfrom ultralytics.utils import callbacks\n\n# -------------------------------------------------\n# 1. Free space (avoid disk full)\n# -------------------------------------------------\nshutil.rmtree(RUNS, ignore_errors=True)\nshutil.rmtree(\"/root/.cache/torch/hub\", ignore_errors=True)\n\n# -------------------------------------------------\n# 2. Disable RayTune callback (to fix AttributeError)\n# -------------------------------------------------\nif \"on_fit_epoch_end\" in callbacks.default_callbacks:\n    del callbacks.default_callbacks[\"on_fit_epoch_end\"]\nprint(\"✔ Disabled RayTune callback\")\n\n# -------------------------------------------------\n# 3. Training settings\n# -------------------------------------------------\nBASE_MODEL = \"yolov8m.pt\"   # using medium model\nEPOCHS     = 30             # train for 30 more epochs\nBATCH      = 8\n\n# -------------------------------------------------\n# 4. Load model\n# -------------------------------------------------\nmodel = YOLO(BASE_MODEL)\n\n# -------------------------------------------------\n# 5. Train\n# -------------------------------------------------\nresults = model.train(\n    data=\"/kaggle/working/c2a_data.yaml\",\n    epochs=20,        # try smaller first (20 instead of 50)\n    imgsz=640,\n    batch=8,          # smaller batch uses less GPU + saves space\n    device=0,\n    project=\"/kaggle/working/runs\",\n    name=\"c2a_train\",\n    save=True,\n    save_period=0,\n    val=True,\n    verbose=True\n)\n\n\n# -------------------------------------------------\n# 6. Paths to weights\n# -------------------------------------------------\nrun_dir = RUNS / \"detect\" / \"c2a_train_m\"\nweights = run_dir / \"weights\"\nbest_pt = weights / \"best.pt\"\nlast_pt = weights / \"last.pt\"\n\nprint(\"\\n==> Run dir:\", run_dir)\nprint(\"==> Weights:\", weights)\nprint(\"✔ best.pt:\", best_pt.exists(), \" | ✔ last.pt:\", last_pt.exists())\n\n# -------------------------------------------------\n# 7. Zip best.pt for download\n# -------------------------------------------------\nif best_pt.exists():\n    zip_path = \"/kaggle/working/best_weights\"\n    shutil.make_archive(zip_path, 'zip', weights)\n    print(f\"✔ Zipped best.pt at {zip_path}.zip — ready to download!\")\nelse:\n    print(\"⚠ best.pt not found yet\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T14:17:53.108061Z","iopub.execute_input":"2025-08-23T14:17:53.108347Z","iopub.status.idle":"2025-08-23T14:23:08.410669Z","shell.execute_reply.started":"2025-08-23T14:17:53.108310Z","shell.execute_reply":"2025-08-23T14:23:08.409418Z"}},"outputs":[{"name":"stdout","text":"✔ Disabled RayTune callback\nNew https://pypi.org/project/ultralytics/8.3.184 available 😃 Update with 'pip install -U ultralytics'\nUltralytics 8.3.50 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/kaggle/working/c2a_data.yaml, epochs=20, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=0, cache=False, device=0, workers=8, project=/kaggle/working/runs, name=c2a_train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/runs/c2a_train\nOverriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 295 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /kaggle/working/runs/c2a_train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/c2a_preprocessed/train/labels.cache... 6129 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6129/6129 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/c2a_preprocessed/train/images/flood_image0407_3.png: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n  A.ImageCompression(quality_lower=75, p=0.0),\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/c2a_preprocessed/val/labels.cache... 2043 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2043/2043 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/runs/c2a_train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/c2a_train\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/20      5.91G      1.284      0.928      1.028         75        640: 100%|██████████| 767/767 [04:27<00:00,  2.87it/s] \n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:35<00:00,  3.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       2043      72123      0.774      0.667      0.717      0.438\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/354750489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# 5. Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# -------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m results = model.train(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/c2a_data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;31m# try smaller first (20 instead of 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m  \u001b[0;31m# do not move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m  \u001b[0;31m# stop if exceeded epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_fit_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mrun_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;34m\"\"\"Run all existing callbacks associated with a particular event.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/callbacks/raytune.py\u001b[0m in \u001b[0;36mon_fit_epoch_end\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mon_fit_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m\"\"\"Sends training metrics to Ray Tune at end of each epoch.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# replacement for deprecated ray.tune.is_session_enabled()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'ray.train._internal.session' has no attribute '_get_session'"],"ename":"AttributeError","evalue":"module 'ray.train._internal.session' has no attribute '_get_session'","output_type":"error"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}